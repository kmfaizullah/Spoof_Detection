{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "from pickle import dump\n",
    "import keras\n",
    "import glob\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.applications.resnet import ResNet50\n",
    "from keras.preprocessing.image import load_img\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "from keras.models import Model\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import warnings\n",
    "import time\n",
    "import glob\n",
    "from PIL import Image\n",
    "from src.generate_patches import CropImage\n",
    "import math\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Detection:\n",
    "    def __init__(self):\n",
    "        caffemodel = \"./resources/detection_model/Widerface-RetinaFace.caffemodel\"\n",
    "        deploy = \"./resources/detection_model/deploy.prototxt\"\n",
    "        self.detector = cv2.dnn.readNetFromCaffe(deploy, caffemodel)\n",
    "        self.detector_confidence = 0.9\n",
    "\n",
    "    def get_bbox(self, img):\n",
    "        height, width = img.shape[0], img.shape[1]\n",
    "        aspect_ratio = width / height\n",
    "        if img.shape[1] * img.shape[0] >= 192 * 192:\n",
    "            img = cv2.resize(img,\n",
    "                             (int(192 * math.sqrt(aspect_ratio)),\n",
    "                              int(192 / math.sqrt(aspect_ratio))), interpolation=cv2.INTER_LINEAR)\n",
    "\n",
    "        blob = cv2.dnn.blobFromImage(img, 1, mean=(104, 117, 123))\n",
    "        self.detector.setInput(blob, 'data')\n",
    "        out = self.detector.forward('detection_out').squeeze()\n",
    "        max_conf_index = np.argmax(out[:, 2])\n",
    "        left, top, right, bottom = out[max_conf_index, 3]*width, out[max_conf_index, 4]*height, \\\n",
    "                                   out[max_conf_index, 5]*width, out[max_conf_index, 6]*height\n",
    "        bbox = [int(left), int(top), int(right-left+1), int(bottom-top+1)]\n",
    "        return bbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_cropper = CropImage()\n",
    "model_test = Detection()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_crop_face(frame):\n",
    "    image_bbox = model_test.get_bbox(frame)\n",
    "    h_input, w_input, _ = frame.shape\n",
    "    param = {\n",
    "    \"org_img\": frame,\n",
    "    \"bbox\": image_bbox,\n",
    "    \"scale\": 1.0,\n",
    "    \"out_w\": w_input,\n",
    "    \"out_h\": h_input,\n",
    "    \"crop\": True,\n",
    "    }\n",
    "    crop = image_cropper.crop(**param)\n",
    "    return crop, image_bbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "path='/home/mle/Desktop/fast.ai_course/face_extractor/extractor/dataset/test/spoof/anomaly/spoof.mp4'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cam = cv2.VideoCapture(path)\n",
    "\n",
    "\n",
    "currentframe = 0\n",
    "\n",
    "out_put_dir = f'dataset/test_spoof/'\n",
    "os.makedirs(out_put_dir, exist_ok=True) \n",
    "val= []\n",
    "face_crop = []\n",
    "val = 0\n",
    "#print(\"yes\")\n",
    "while(True): \n",
    "\n",
    "    # reading from frame \n",
    "    ret,img = cam.read() \n",
    "\n",
    "    if ret:\n",
    "        frame = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "        crop, image_bbox = get_crop_face(frame)\n",
    "        if image_bbox == [0,0,1,1]:\n",
    "            continue\n",
    "        vidlast = path.split(\"/\")[-1].split(\".\")[0]\n",
    "        crop = cv2.resize(crop, (224,224))\n",
    "        crop = cv2.cvtColor(crop, cv2.COLOR_BGR2RGB)\n",
    "        cv2.imwrite(f\"{out_put_dir}/{vidlast}_{val}.png\",crop)\n",
    "        currentframe += 1\n",
    "        val = val+1\n",
    "        #print(val)\n",
    "    else: \n",
    "        break\n",
    "    #break\n",
    "cam.release() \n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_size=224\n",
    "model = ResNet50()\n",
    "#Modify model to remove the last layer\n",
    "model.layers.pop()\n",
    "model = Model(inputs=model.inputs,outputs=model.layers[-1].output)\n",
    "# print(model.summary())\n",
    "\n",
    "# extracting feature of real\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_img = \"./dataset/test/real/aczrgyricp/\"\n",
    "# test_img = \"./dataset/test_spoof/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "dirs = os.listdir(test_img)\n",
    "for img in dirs:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/115 [00:00<?, ?it/s]\u001b[A\n",
      "  1%|          | 1/115 [00:00<00:38,  2.94it/s]\u001b[A\n",
      "  2%|▏         | 2/115 [00:00<00:36,  3.10it/s]\u001b[A\n",
      "  3%|▎         | 3/115 [00:00<00:35,  3.18it/s]\u001b[A\n",
      "  3%|▎         | 4/115 [00:01<00:34,  3.26it/s]\u001b[A\n",
      "  4%|▍         | 5/115 [00:01<00:38,  2.87it/s]\u001b[A\n",
      "  5%|▌         | 6/115 [00:01<00:36,  2.96it/s]\u001b[A\n",
      "  6%|▌         | 7/115 [00:02<00:35,  3.06it/s]\u001b[A\n",
      "  7%|▋         | 8/115 [00:02<00:33,  3.17it/s]\u001b[A\n",
      "  8%|▊         | 9/115 [00:02<00:32,  3.22it/s]\u001b[A\n",
      "  9%|▊         | 10/115 [00:03<00:32,  3.25it/s]\u001b[A\n",
      " 10%|▉         | 11/115 [00:03<00:31,  3.31it/s]\u001b[A\n",
      " 10%|█         | 12/115 [00:03<00:30,  3.36it/s]\u001b[A\n",
      " 11%|█▏        | 13/115 [00:04<00:30,  3.38it/s]\u001b[A\n",
      " 12%|█▏        | 14/115 [00:04<00:29,  3.38it/s]\u001b[A\n",
      " 13%|█▎        | 15/115 [00:04<00:29,  3.36it/s]\u001b[A\n",
      " 14%|█▍        | 16/115 [00:04<00:29,  3.37it/s]\u001b[A\n",
      " 15%|█▍        | 17/115 [00:05<00:28,  3.44it/s]\u001b[A\n",
      " 16%|█▌        | 18/115 [00:05<00:28,  3.39it/s]\u001b[A\n",
      " 17%|█▋        | 19/115 [00:05<00:28,  3.42it/s]\u001b[A\n",
      " 17%|█▋        | 20/115 [00:06<00:27,  3.46it/s]\u001b[A\n",
      " 18%|█▊        | 21/115 [00:06<00:29,  3.16it/s]\u001b[A\n",
      " 19%|█▉        | 22/115 [00:06<00:29,  3.21it/s]\u001b[A\n",
      " 20%|██        | 23/115 [00:07<00:30,  2.98it/s]\u001b[A\n",
      " 21%|██        | 24/115 [00:07<00:31,  2.92it/s]\u001b[A\n",
      " 22%|██▏       | 25/115 [00:07<00:31,  2.87it/s]\u001b[A\n",
      " 23%|██▎       | 26/115 [00:08<00:31,  2.84it/s]\u001b[A\n",
      " 23%|██▎       | 27/115 [00:08<00:31,  2.80it/s]\u001b[A\n",
      " 24%|██▍       | 28/115 [00:08<00:31,  2.72it/s]\u001b[A\n",
      " 25%|██▌       | 29/115 [00:09<00:31,  2.73it/s]\u001b[A\n",
      " 26%|██▌       | 30/115 [00:09<00:31,  2.72it/s]\u001b[A\n",
      " 27%|██▋       | 31/115 [00:10<00:31,  2.68it/s]\u001b[A\n",
      " 28%|██▊       | 32/115 [00:10<00:30,  2.72it/s]\u001b[A\n",
      " 29%|██▊       | 33/115 [00:10<00:30,  2.71it/s]\u001b[A\n",
      " 30%|██▉       | 34/115 [00:11<00:28,  2.82it/s]\u001b[A\n",
      " 30%|███       | 35/115 [00:11<00:30,  2.65it/s]\u001b[A\n",
      " 31%|███▏      | 36/115 [00:11<00:29,  2.71it/s]\u001b[A\n",
      " 32%|███▏      | 37/115 [00:12<00:28,  2.78it/s]\u001b[A\n",
      " 33%|███▎      | 38/115 [00:12<00:26,  2.85it/s]\u001b[A\n",
      " 34%|███▍      | 39/115 [00:12<00:26,  2.89it/s]\u001b[A\n",
      " 35%|███▍      | 40/115 [00:13<00:25,  2.96it/s]\u001b[A\n",
      " 36%|███▌      | 41/115 [00:13<00:24,  2.98it/s]\u001b[A\n",
      " 37%|███▋      | 42/115 [00:13<00:24,  2.98it/s]\u001b[A\n",
      " 37%|███▋      | 43/115 [00:14<00:25,  2.81it/s]\u001b[A\n",
      " 38%|███▊      | 44/115 [00:14<00:26,  2.72it/s]\u001b[A\n",
      " 39%|███▉      | 45/115 [00:15<00:24,  2.84it/s]\u001b[A\n",
      " 40%|████      | 46/115 [00:15<00:22,  3.01it/s]\u001b[A\n",
      " 41%|████      | 47/115 [00:15<00:21,  3.15it/s]\u001b[A\n",
      " 42%|████▏     | 48/115 [00:15<00:20,  3.26it/s]\u001b[A\n",
      " 43%|████▎     | 49/115 [00:16<00:19,  3.30it/s]\u001b[A\n",
      " 43%|████▎     | 50/115 [00:16<00:19,  3.36it/s]\u001b[A\n",
      " 44%|████▍     | 51/115 [00:16<00:18,  3.38it/s]\u001b[A\n",
      " 45%|████▌     | 52/115 [00:17<00:18,  3.41it/s]\u001b[A\n",
      " 46%|████▌     | 53/115 [00:17<00:18,  3.28it/s]\u001b[A\n",
      " 47%|████▋     | 54/115 [00:17<00:19,  3.20it/s]\u001b[A\n",
      " 48%|████▊     | 55/115 [00:18<00:18,  3.22it/s]\u001b[A\n",
      " 49%|████▊     | 56/115 [00:18<00:17,  3.32it/s]\u001b[A\n",
      " 50%|████▉     | 57/115 [00:18<00:17,  3.34it/s]\u001b[A\n",
      " 50%|█████     | 58/115 [00:18<00:19,  2.99it/s]\u001b[A\n",
      " 51%|█████▏    | 59/115 [00:19<00:18,  2.98it/s]\u001b[A\n",
      " 52%|█████▏    | 60/115 [00:19<00:18,  3.00it/s]\u001b[A\n",
      " 53%|█████▎    | 61/115 [00:19<00:17,  3.03it/s]\u001b[A\n",
      " 54%|█████▍    | 62/115 [00:20<00:17,  3.03it/s]\u001b[A\n",
      " 55%|█████▍    | 63/115 [00:20<00:17,  2.95it/s]\u001b[A\n",
      " 56%|█████▌    | 64/115 [00:21<00:18,  2.81it/s]\u001b[A\n",
      " 57%|█████▋    | 65/115 [00:21<00:17,  2.82it/s]\u001b[A\n",
      " 57%|█████▋    | 66/115 [00:21<00:17,  2.88it/s]\u001b[A\n",
      " 58%|█████▊    | 67/115 [00:22<00:16,  2.94it/s]\u001b[A\n",
      " 59%|█████▉    | 68/115 [00:22<00:15,  2.95it/s]\u001b[A\n",
      " 60%|██████    | 69/115 [00:22<00:16,  2.71it/s]\u001b[A\n",
      " 61%|██████    | 70/115 [00:23<00:19,  2.35it/s]\u001b[A\n",
      " 62%|██████▏   | 71/115 [00:23<00:19,  2.30it/s]\u001b[A\n",
      " 63%|██████▎   | 72/115 [00:24<00:18,  2.32it/s]\u001b[A\n",
      " 63%|██████▎   | 73/115 [00:24<00:18,  2.28it/s]\u001b[A\n",
      " 64%|██████▍   | 74/115 [00:25<00:19,  2.07it/s]\u001b[A\n",
      " 65%|██████▌   | 75/115 [00:25<00:19,  2.10it/s]\u001b[A\n",
      " 66%|██████▌   | 76/115 [00:26<00:18,  2.14it/s]\u001b[A\n",
      " 67%|██████▋   | 77/115 [00:26<00:18,  2.09it/s]\u001b[A\n",
      " 68%|██████▊   | 78/115 [00:27<00:16,  2.21it/s]\u001b[A\n",
      " 69%|██████▊   | 79/115 [00:27<00:15,  2.32it/s]\u001b[A\n",
      " 70%|██████▉   | 80/115 [00:27<00:14,  2.43it/s]\u001b[A\n",
      " 70%|███████   | 81/115 [00:28<00:13,  2.51it/s]\u001b[A\n",
      " 71%|███████▏  | 82/115 [00:28<00:12,  2.59it/s]\u001b[A\n",
      " 72%|███████▏  | 83/115 [00:28<00:12,  2.62it/s]\u001b[A\n",
      " 73%|███████▎  | 84/115 [00:29<00:13,  2.30it/s]\u001b[A\n",
      " 74%|███████▍  | 85/115 [00:29<00:12,  2.35it/s]\u001b[A\n",
      " 75%|███████▍  | 86/115 [00:30<00:11,  2.45it/s]\u001b[A\n",
      " 76%|███████▌  | 87/115 [00:30<00:11,  2.53it/s]\u001b[A\n",
      " 77%|███████▋  | 88/115 [00:31<00:10,  2.61it/s]\u001b[A\n",
      " 77%|███████▋  | 89/115 [00:31<00:09,  2.72it/s]\u001b[A\n",
      " 78%|███████▊  | 90/115 [00:31<00:08,  2.80it/s]\u001b[A\n",
      " 79%|███████▉  | 91/115 [00:32<00:08,  2.87it/s]\u001b[A\n",
      " 80%|████████  | 92/115 [00:32<00:08,  2.83it/s]\u001b[A\n",
      " 81%|████████  | 93/115 [00:32<00:08,  2.74it/s]\u001b[A\n",
      " 82%|████████▏ | 94/115 [00:33<00:07,  2.75it/s]\u001b[A\n",
      " 83%|████████▎ | 95/115 [00:33<00:07,  2.84it/s]\u001b[A\n",
      " 83%|████████▎ | 96/115 [00:33<00:06,  2.91it/s]\u001b[A\n",
      " 84%|████████▍ | 97/115 [00:34<00:06,  2.94it/s]\u001b[A\n",
      " 85%|████████▌ | 98/115 [00:34<00:05,  2.88it/s]\u001b[A\n",
      " 86%|████████▌ | 99/115 [00:34<00:05,  2.82it/s]\u001b[A\n",
      " 87%|████████▋ | 100/115 [00:35<00:05,  2.93it/s]\u001b[A\n",
      " 88%|████████▊ | 101/115 [00:35<00:04,  2.85it/s]\u001b[A\n",
      " 89%|████████▊ | 102/115 [00:35<00:04,  2.94it/s]\u001b[A\n",
      " 90%|████████▉ | 103/115 [00:36<00:04,  3.00it/s]\u001b[A\n",
      " 90%|█████████ | 104/115 [00:36<00:03,  3.15it/s]\u001b[A\n",
      " 91%|█████████▏| 105/115 [00:36<00:03,  3.22it/s]\u001b[A\n",
      " 92%|█████████▏| 106/115 [00:37<00:03,  2.98it/s]\u001b[A\n",
      " 93%|█████████▎| 107/115 [00:37<00:02,  3.10it/s]\u001b[A\n",
      " 94%|█████████▍| 108/115 [00:37<00:02,  3.15it/s]\u001b[A\n",
      " 95%|█████████▍| 109/115 [00:38<00:01,  3.23it/s]\u001b[A\n",
      " 96%|█████████▌| 110/115 [00:38<00:01,  3.26it/s]\u001b[A\n",
      " 97%|█████████▋| 111/115 [00:38<00:01,  3.01it/s]\u001b[A\n",
      " 97%|█████████▋| 112/115 [00:39<00:01,  2.96it/s]\u001b[A\n",
      " 98%|█████████▊| 113/115 [00:39<00:00,  2.94it/s]\u001b[A\n",
      " 99%|█████████▉| 114/115 [00:39<00:00,  2.96it/s]\u001b[A\n",
      "100%|██████████| 115/115 [00:40<00:00,  2.96it/s]\u001b[A"
     ]
    }
   ],
   "source": [
    "features=[]\n",
    "for img_name in tqdm(dirs):\n",
    "    image = load_img(test_img+img_name,target_size=(target_size,target_size))\n",
    "    image = img_to_array(image)\n",
    "    image = image.reshape((1, image.shape[0], image.shape[1], image.shape[2]))\n",
    "    # prepare the image for the VGG model\n",
    "    image = preprocess_input(image)\n",
    "    # get features\n",
    "    img_feature = model.predict(image, verbose=0)\n",
    "    # store feature\n",
    "    features.append(img_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"best_model.pkl\"\n",
    "loaded_model = pickle.load(open(filename, 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done   2 out of   4 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done   4 out of   4 | elapsed:    0.0s finished\n"
     ]
    }
   ],
   "source": [
    "positive_features_test = [fes.reshape(-1) for fes in features]\n",
    "predicted = loaded_model.predict(positive_features_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = np.average(predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Real\n"
     ]
    }
   ],
   "source": [
    "if result>0.5:\n",
    "    print(\"Spoof\")\n",
    "else:\n",
    "    print(\"Real\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
